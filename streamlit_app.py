import streamlit as st
import pandas as pd
import glob
import os
from datetime import datetime, timedelta

st.set_page_config(layout="wide")

PASSWORD = "ycenc1308"

def login():
    st.title("ğŸˆ ì§€ìì²´ í¬ë¡¤ë§ ë¡œê·¸ì¸")
    password = st.text_input("ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password")
    if st.button("ë¡œê·¸ì¸"):
        if password == PASSWORD:
            st.session_state.logged_in = True
            st.success("ë¡œê·¸ì¸ ì„±ê³µ!")
        else:
            st.error("ë¹„ë°€ë²ˆí˜¸ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

def main_app():
    st.title("ğŸˆ ì§€ìì²´ í¬ë¡¤ë§")
    update_time = st.session_state.get('update_time', "2024ë…„ 10ì›” 27ì¼ 22:28 ì—…ë°ì´íŠ¸")
    st.write(f"{update_time}\n")
    st.write("ì‘ì—…ì§„í–‰ìƒí™© : 211ê°œ ì „ì²´ site ìµœì‹  1page ìˆ˜ì§‘ ì‘ì—… ì™„ë£Œ(1ì°¨ì™„ë£Œ) \n")
    st.write("í–¥í›„ì§„í–‰ê³„íš : ìˆ˜ì§‘ì‹¤íŒ¨ì‚¬ì´íŠ¸ì ê²€, 2pageì´ìƒ ìˆ˜ì§‘í•˜ë„ë¡ ë³€ê²½")
    
    # ì˜¤ëŠ˜ ì¼ì ë° ìµœê·¼ 7ì¼ ê³„ì‚°
    today = datetime.today()
    one_week_ago = today - timedelta(days=7)
    today_str = today.strftime('%Y%m%d')
    
   # íŠ¹ì • ì ‘ë‘ì‚¬ë¥¼ ê°€ì§€ëŠ” ìµœê·¼ íŒŒì¼ë“¤ì„ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    def get_recent_files_by_date(file_prefix):
        files = glob.glob(f"{file_prefix}_*.xlsx")
        file_dates = []
        for file in files:
            file_date_str = file.split('_')[-1].replace('.xlsx', '')
            try:
                file_date = datetime.strptime(file_date_str, '%Y%m%d')
                if one_week_ago <= file_date <= today:
                    file_dates.append(file_date_str)
            except ValueError:
                continue
        return sorted(set(file_dates), reverse=True)
    
    # ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì˜ íŒŒì¼ì„ ì½ì–´ì˜¤ê¸° ìœ„í•œ í•¨ìˆ˜
    def get_recent_files(file_prefix):
        files = glob.glob(f"{file_prefix}_*.xlsx")
        recent_files = []
        for file in files:
            file_date_str = file.split('_')[-1].replace('.xlsx', '')
            try:
                file_date = datetime.strptime(file_date_str, '%Y%m%d')
                if one_week_ago <= file_date <= today:
                    recent_files.append(file)
            except ValueError:
                continue
        return sorted(recent_files, reverse=True)
    
    # df_log íŒŒì¼ì—ì„œ ìµœê·¼ ë‚ ì§œ ëª©ë¡ì„ ê°€ì ¸ì˜¤ê¸°
    available_dates = get_recent_files_by_date('df_log')
    
    if available_dates:
        # ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‚ ì§œì— ë”°ë¥¸ íŒŒì¼ ëª©ë¡ í‘œì‹œ
        selected_date = st.selectbox("ë‚ ì§œë¥¼ ì„ íƒí•˜ì„¸ìš”", available_dates)
        
        # ì„ íƒëœ ë‚ ì§œì— í•´ë‹¹í•˜ëŠ” df_log íŒŒì¼ ì½ê¸°
        df_log_files = glob.glob(f"df_log_{selected_date}.xlsx")
        
        if df_log_files:
            st.write(f"ì„ íƒí•œ ë‚ ì§œ: {selected_date}")
            
            combined_df_log = pd.DataFrame()
            for file_path in df_log_files:
                df = pd.read_excel(file_path, engine='openpyxl')
                df['íŒŒì¼ëª…'] = os.path.basename(file_path)
                combined_df_log = pd.concat([combined_df_log, df], ignore_index=True)
            
            # Check problematic rows
            problematic_rows = combined_df_log[
                (combined_df_log['unique_date'].isnull()) | (combined_df_log['unique_date'] == 1) | (combined_df_log['unique_date'] == 0)
            ]
            
            if not problematic_rows.empty:
                st.warning(f"ì„ íƒí•œ ë‚ ì§œ({selected_date})ì— ëœ ìˆ˜ì§‘ëœ ì‚¬ì´íŠ¸ ë¦¬ìŠ¤íŠ¸ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤. ì§ì ‘ ì ‘ì† í›„ í™•ì¸ í•„ìš”í•©ë‹ˆë‹¤.")
                st.write("í™•ì¸í•´ì•¼ í•  ì‚¬ì´íŠ¸:")
                st.dataframe(problematic_rows, use_container_width=True)
            else:
                st.success(f"ì„ íƒí•œ ë‚ ì§œ({selected_date})ì—ëŠ” unique_dateê°€ Nullì´ê±°ë‚˜ 1ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.write(f"ì„ íƒí•œ ë‚ ì§œ({selected_date})ì— í•´ë‹¹í•˜ëŠ” df_log íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.write("ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì— df_log íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # df_list íŒŒì¼ ì½ê¸° ë° ì²˜ë¦¬
    df_list_file_paths = get_recent_files('df_list')
    if df_list_file_paths:
        combined_df_list = pd.DataFrame()
        
        for file_path in df_list_file_paths:
            df = pd.read_excel(file_path, engine='openpyxl')
            combined_df_list = pd.concat([combined_df_list, df], ignore_index=True)
        
        combined_df_list = combined_df_list.drop_duplicates()
    
        column_order = ['SITE_NO', 'ì¶œì²˜', 'ì œëª©', 'URL', 'ì‘ì„±ì¼']
        combined_df_list = combined_df_list.reindex(columns=column_order)
    
        combined_df_list['URL'] = combined_df_list['URL'].apply(lambda x: f'<a href="{x}" target="_blank">{x}</a>')
    
        combined_df_list['ì‘ì„±ì¼'] = pd.to_datetime(combined_df_list['ì‘ì„±ì¼'], errors='coerce')
        combined_df_list = combined_df_list.sort_values(by='ì‘ì„±ì¼', ascending=False)
    
        st.markdown("""
            <style>
            table {
                width: 100%;
            }
            th, td {
                padding: 5px;
            }
            th {
                text-align: left;
            }
            td {
                max-width: 200px;
                overflow-wrap: break-word;
            }
            </style>
        """, unsafe_allow_html=True)
        
        st.write(f"ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì— df_list íŒŒì¼ {len(df_list_file_paths)}ê°œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
        
        search_keyword = st.text_input("df_list íŒŒì¼ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”")
    
        if search_keyword:
            search_results = combined_df_list[combined_df_list['ì œëª©'].str.contains(search_keyword, na=False)]
            st.write(f"'{search_keyword}' ê²€ìƒ‰ ê²°ê³¼:")
            st.markdown(search_results.to_html(escape=False), unsafe_allow_html=True)
        else:
            st.write("df_list íŒŒì¼ì˜ ì „ì²´ ë°ì´í„°:")
            st.markdown(combined_df_list.to_html(escape=False), unsafe_allow_html=True)
    else:
        st.write("ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì— df_list íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
   # ì¤‘ê°„ ì¼ë°°ì¹˜ ìˆ˜ì§‘ ë¡œê·¸ í…ìŠ¤íŠ¸ ê´€ë¦¬
    log_text = """
   Processing rows:   0%|          | 0/211 [00:00<?, ?it/s]<ipython-input-5-c0391dc5c3fd>:112: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2023-03-17' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  df.at[index, 'min_date'] = min_date
<ipython-input-5-c0391dc5c3fd>:113: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '2024-09-03' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.
  df.at[index, 'max_date'] = max_date
Processing rows:  20%|â–ˆâ–ˆ        | 43/211 [04:30<21:53,  7.82s/it]ê²½ê¸°ë„_ê´‘ëª…ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  22%|â–ˆâ–ˆâ–       | 47/211 [04:38<08:54,  3.26s/it]ìš”ì²­ ì˜¤ë¥˜: 417 Client Error: Expectation Failed for url: https://www.gimpo.go.kr/portal/ntfcPblancList.do?key=1004&cate_cd=1&searchCnd=40900000000
ê²½ê¸°ë„_ê¹€í¬ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  28%|â–ˆâ–ˆâ–Š       | 59/211 [06:34<23:57,  9.46s/it]ì—°ê²° íƒ€ì„ì•„ì›ƒ: ê²½ê¸°ë„_ì•ˆì„±ì‹œ ì„œë²„ë¡œë¶€í„° ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.
ê²½ê¸°ë„_ì•ˆì„±ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  32%|â–ˆâ–ˆâ–ˆâ–      | 67/211 [07:48<21:52,  9.12s/it]í˜ì´ì§€ ë¡œë”© ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤: ê²½ê¸°ë„_í‰íƒì‹œ
Processing rows:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 90/211 [12:09<17:02,  8.45s/it]ì½ê¸° íƒ€ì„ì•„ì›ƒ: ê°•ì›ë„_í™ì²œêµ° ì„œë²„ê°€ ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.
ê°•ì›ë„_í™ì²œêµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 114/211 [17:42<22:17, 13.79s/it]WARNING:urllib3.connection:Failed to parse headers (url=https://www.geumsan.go.kr:443/kr/html/sub03/030302.html): [MissingHeaderBodySeparatorDefect()], unparsed data: 'P3P : CP="NOI CURa ADMa DEVa TAIa OUR DELa BUS IND PHY ONL UNI COM NAV INT DEM PRE"\r\nSet-Cookie: SIDNAME=ronty; path=/; HttpOnly; secure; SameSite=None; secure\r\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\r\nPragma: no-cache\r\nSet-Cookie: PHPSESSID=vl6re9loeqlon179jjbui0o2e4; path=/; HttpOnly; secure; SameSite=None\r\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\r\n\r\n'
Traceback (most recent call last):
  File "/usr/local/lib/python3.10/dist-packages/urllib3/connection.py", line 510, in getresponse
    assert_header_parsing(httplib_response.msg)
  File "/usr/local/lib/python3.10/dist-packages/urllib3/util/response.py", line 88, in assert_header_parsing
    raise HeaderParsingError(defects=defects, unparsed_data=unparsed_data)
urllib3.exceptions.HeaderParsingError: [MissingHeaderBodySeparatorDefect()], unparsed data: 'P3P : CP="NOI CURa ADMa DEVa TAIa OUR DELa BUS IND PHY ONL UNI COM NAV INT DEM PRE"\r\nSet-Cookie: SIDNAME=ronty; path=/; HttpOnly; secure; SameSite=None; secure\r\nCache-Control: no-store, no-cache, must-revalidate, post-check=0, pre-check=0\r\nPragma: no-cache\r\nSet-Cookie: PHPSESSID=vl6re9loeqlon179jjbui0o2e4; path=/; HttpOnly; secure; SameSite=None\r\nExpires: Thu, 19 Nov 1981 08:52:00 GMT\r\n\r\n'
Processing rows:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 122/211 [19:15<18:59, 12.80s/it]ì „ë¼ë„_êµ°ì‚°ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 124/211 [19:20<10:48,  7.46s/it]ìš”ì²­ ì˜¤ë¥˜: 400 Client Error: Bad Request for url: https://www.namwon.go.kr/board/post/list.do?boardUid=ff8080818ea1fec5018ea24137680031&menuUid=ff8080818e3beff0018e4077131b007a&beginDateStr=&endDateStr=&searchType=postTtl&keyword=%EC%A0%9C%EC%95%88&paramString=Us7WVBAxc13kgzv1JU3ayAslPphGSM%2FmlfdB4qtWC4OBeJsElaKmGl7kvQ4Au%2B3O&size=10
ì „ë¼ë„_ë‚¨ì›ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 126/211 [20:11<22:20, 15.77s/it]ì—°ê²° íƒ€ì„ì•„ì›ƒ: ì „ë¼ë„_ì „ì£¼ì‹œ ì„œë²„ë¡œë¶€í„° ì‘ë‹µì´ ì—†ìŠµë‹ˆë‹¤.
ì „ë¼ë„_ì „ì£¼ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 129/211 [20:50<19:10, 14.03s/it]cleaned_dates ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.
Processing rows:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 133/211 [21:45<19:55, 15.33s/it]ì „ë¼ë„_ì„ì‹¤êµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 140/211 [23:12<11:43,  9.91s/it]ìš”ì²­ ì˜¤ë¥˜: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect data check'))
ì „ë¼ë„_ì—¬ìˆ˜ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 146/211 [24:04<09:35,  8.86s/it]ìš”ì²­ ì˜¤ë¥˜: ('Received response with content-encoding: gzip, but failed to decode it.', error('Error -3 while decompressing data: incorrect data check'))
ì „ë¼ë„_ë¬´ì•ˆêµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 147/211 [24:14<10:00,  9.38s/it]ì½ê¸° íƒ€ì„ì•„ì›ƒ: ì „ë¼ë„_ë³´ì„±êµ° ì„œë²„ê°€ ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.
ì „ë¼ë„_ë³´ì„±êµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 157/211 [25:17<07:09,  7.95s/it]ì „ë¼ë„_í™”ìˆœêµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 162/211 [25:50<05:09,  6.31s/it]ìš”ì²­ ì˜¤ë¥˜: 404 Client Error: Not Found for url: https://www.gbmg.go.kr/portal/saeol/gosi/list.do?mId=0301060000
ê²½ìƒë„_ë¬¸ê²½ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 166/211 [26:01<02:23,  3.19s/it]ê²½ìƒë„_ì˜ì²œì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 170/211 [26:37<05:05,  7.45s/it]cleaned_dates ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.
Processing rows:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 171/211 [26:49<05:49,  8.73s/it]cleaned_dates ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.
Processing rows:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 173/211 [27:03<05:11,  8.21s/it]cleaned_dates ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.
Processing rows:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 177/211 [27:51<06:17, 11.09s/it]cleaned_dates ë¦¬ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.
Processing rows:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 178/211 [28:04<06:28, 11.76s/it]ê²½ìƒë„_ì²­ì†¡êµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 193/211 [28:47<00:57,  3.21s/it]ìš”ì²­ ì˜¤ë¥˜: HTTPSConnectionPool(host='www.namhae.go.kr', port=443): Max retries exceeded with url: /modules/saeol/gosi.do?dep_nm=%EB%82%A8%ED%95%B4%EC%9D%8D&pageCd=WW0512010103&siteGubun=portal (Caused by NameResolutionError("<urllib3.connection.HTTPSConnection object at 0x7cf3b8176020>: Failed to resolve 'www.namhae.go.kr' ([Errno -2] Name or service not known)"))
ê²½ìƒë„_ë‚¨í•´êµ°_ë‚¨í•´ìí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 211/211 [29:58<00:00,  8.53s/it]
    """
    

    st.session_state.log_text = log_text
        
    st.text(log_text)

# ë©”ì¸ ì‹¤í–‰ íë¦„
if 'logged_in' not in st.session_state:
    st.session_state.logged_in = False

if not st.session_state.logged_in:
    login()
else:
    st.session_state.update_time = "2024ë…„ 10ì›” 27ì¼ 22:28 ì—…ë°ì´íŠ¸"  # ì›í•˜ëŠ” ì‹œê°„ìœ¼ë¡œ ë³€ê²½
    main_app()
