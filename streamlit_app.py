import streamlit as st
import pandas as pd
import glob
import os
from datetime import datetime, timedelta

st.title("ğŸˆ ì§€ìì²´ í¬ë¡¤ë§")
st.write("2024ë…„ 10ì›” 7ì¼ 23:58 ì—…ë°ì´íŠ¸\n")
st.write("ì‘ì—…ì§„í–‰ìƒí™© : 93ê°œ site ìµœì‹  1page ìˆ˜ì§‘ ì‘ì—… ì™„ë£Œ\n")
st.write("í–¥í›„ì§„í–‰ê³„íš : ë‚˜ë¨¸ì§€ site ìµœì‹  í˜ì´ì§€ ìˆ˜ì§‘, ìˆ˜ì§‘ì‹¤íŒ¨ì‚¬ì´íŠ¸ì ê²€, 2pageì´ìƒ ìˆ˜ì§‘í•˜ë„ë¡ ë³€ê²½")


# ì˜¤ëŠ˜ ì¼ì ë° ìµœê·¼ 7ì¼ ê³„ì‚°
today = datetime.today()
one_week_ago = today - timedelta(days=7)
today_str = today.strftime('%Y%m%d')

# ìµœê·¼ íŒŒì¼ 2ê°œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
def get_two_recent_files(file_prefix):
    files = glob.glob(f"{file_prefix}_*.xlsx")
    recent_files = []
    for file in files:
        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
        file_date_str = file.split('_')[-1].replace('.xlsx', '')
        try:
            file_date = datetime.strptime(file_date_str, '%Y%m%d')
            if one_week_ago <= file_date <= today:
                recent_files.append(file)
        except ValueError:
            continue
    # ìµœê·¼ 2ê°œì˜ íŒŒì¼ ë°˜í™˜ (ìµœì‹  íŒŒì¼ ìˆœìœ¼ë¡œ ì •ë ¬)
    if len(recent_files) >= 2:
        return sorted(recent_files, reverse=True)[:2]
    elif len(recent_files) == 1:
        return recent_files[0], None
    return None, None

# ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì˜ íŒŒì¼ì„ ì½ì–´ì˜¤ê¸° ìœ„í•œ í•¨ìˆ˜
def get_recent_files(file_prefix):
    files = glob.glob(f"{file_prefix}_*.xlsx")
    recent_files = []
    for file in files:
        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ
        file_date_str = file.split('_')[-1].replace('.xlsx', '')
        try:
            file_date = datetime.strptime(file_date_str, '%Y%m%d')
            if one_week_ago <= file_date <= today:
                recent_files.append(file)
        except ValueError:
            continue
    return sorted(recent_files, reverse=True)

# df_log íŒŒì¼ ì½ê¸°
recent_file_path, previous_file_path = get_two_recent_files('df_log')
    
# ìµœê·¼ íŒŒì¼ ì²˜ë¦¬
if recent_file_path:
    df_log_recent = pd.read_excel(recent_file_path, engine='openpyxl')
    st.write(f"ìµœê·¼ df_log íŒŒì¼: {recent_file_path}ì—ì„œ ë°ì´í„°ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤.")
else:
    st.write("ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì— df_log íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ì´ì „ íŒŒì¼ ì²˜ë¦¬
if previous_file_path:
    df_log_previous = pd.read_excel(previous_file_path, engine='openpyxl')
    st.write(f"ì´ì „ df_log íŒŒì¼: {previous_file_path}ì—ì„œ ë°ì´í„°ë¥¼ ì½ì—ˆìŠµë‹ˆë‹¤.")
else:
    st.write("ì´ì „ df_log íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# df_log íŒŒì¼ ì²˜ë¦¬
if recent_file_path and previous_file_path:
    # íŒŒì¼ë“¤ì„ left joiní•˜ì—¬ ë¹„êµ (í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì²˜ë¦¬)
    merge_columns = ['URL', 'unique_date', 'max_date']  # ë¹„êµí•˜ê³ ì í•˜ëŠ” ì»¬ëŸ¼ë“¤ë§Œ ëª…ì‹œ
    df_merged = pd.merge(df_log_recent, 
                         df_log_previous[merge_columns], 
                         on='URL', 
                         suffixes=('_recent', '_previous'), 
                         how='left')
    
    # ë³€ê²½ëœ ê°’ ë¹„êµ
    st.write("ìµœê·¼ íŒŒì¼ê³¼ ì´ì „ íŒŒì¼ì„ left joiní•œ ë°ì´í„°:")
    st.dataframe(df_merged, use_container_width=True)

    # unique_dateê°€ nullì´ê±°ë‚˜ 1ì´ê³  max_dateê°€ ì˜¤ëŠ˜ ì¼ìì¸ ê²½ìš° í•„í„°ë§
    today_str = today.strftime('%Y-%m-%d')  # ì˜¤ëŠ˜ ì¼ì ë¬¸ìì—´ ë³€í™˜
    problematic_rows = df_merged[(df_merged['unique_date_recent'].isnull()) | ((df_merged['unique_date_recent'] == 1) & (df_merged['max_date_recent'] == today_str))]
    
    # ê²½ê³  ë©”ì‹œì§€ í‘œì‹œ
    if not problematic_rows.empty:
        st.warning(f"unique_dateê°€ Nullì´ê±°ë‚˜ 1ì¸ ê²½ìš°ì´ë©°, max_dateê°€ ì˜¤ëŠ˜ì¸ ë°ì´í„°ê°€ {len(problematic_rows)}ê±´ ìˆìŠµë‹ˆë‹¤. ì‚¬ì´íŠ¸ì—ì„œ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤.")
        st.write("í™•ì¸í•´ì•¼ í•  ë°ì´í„°:")
        st.dataframe(problematic_rows, use_container_width=True)
    else:
        st.success("unique_dateê°€ Nullì´ê±°ë‚˜ 1ì¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

else:
    st.write("ë¹„êµë¥¼ ìœ„í•´ ì´ì „ íŒŒì¼ê³¼ ìµœê·¼ íŒŒì¼ì´ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤.")


# df_list íŒŒì¼ ì½ê¸°
df_list_file_paths = get_recent_files('df_list')
if df_list_file_paths:
    combined_df_list = pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ìƒì„±
    
    for file_path in df_list_file_paths:
        df = pd.read_excel(file_path, engine='openpyxl')
        combined_df_list = pd.concat([combined_df_list, df], ignore_index=True)
    
    # ì¤‘ë³µ ì œê±°
    combined_df_list = combined_df_list.drop_duplicates()
    
    st.write(f"ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì— df_list íŒŒì¼ {len(df_list_file_paths)}ê°œë¥¼ ë¶ˆëŸ¬ì™”ìŠµë‹ˆë‹¤.")
    st.write("ì¤‘ë³µì´ ì œê±°ëœ df_list ë°ì´í„°:")
    st.dataframe(combined_df_list, use_container_width=True)
    
    # ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
    search_keyword = st.text_input("df_list íŒŒì¼ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”")

    if search_keyword:
        # ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•œ í–‰ í•„í„°ë§
        search_results = combined_df_list[combined_df_list['ì œëª©'].str.contains(search_keyword, na=False)]
        st.write(f"'{search_keyword}' ê²€ìƒ‰ ê²°ê³¼:")
        st.dataframe(search_results, use_container_width=True)
    else:
        st.write("df_list íŒŒì¼ì˜ ì „ì²´ ë°ì´í„°:")
        st.dataframe(combined_df_list, use_container_width=True)
else:
    st.write("ìµœê·¼ ì¼ì£¼ì¼ ë‚´ì— df_list íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ì¤‘ê°„ ì¼ë°°ì¹˜ ìˆ˜ì§‘ ë¡œê·¸ í…ìŠ¤íŠ¸
st.subheader("ì¼ë°°ì¹˜ ìˆ˜ì§‘ ë¡œê·¸")
log_text = """
Processing rows:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 43/93 [04:25<06:27,  7.76s/it]ê²½ê¸°ë„_ê´‘ëª…ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 47/93 [04:32<02:26,  3.18s/it]ìš”ì²­ ì˜¤ë¥˜: 417 Client Error: Expectation Failed for url: https://www.gimpo.go.kr/portal/ntfcPblancList.do?key=1004&cate_cd=1&searchCnd=40900000000
ê²½ê¸°ë„_ê¹€í¬ì‹œí˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 87/93 [10:45<01:14, 12.46s/it]ê°•ì›ë„_ì •ì„ êµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 90/93 [11:02<00:25,  8.54s/it]ì½ê¸° íƒ€ì„ì•„ì›ƒ: ê°•ì›ë„_í™ì²œêµ° ì„œë²„ê°€ ë°ì´í„°ë¥¼ ì œê³µí•˜ëŠ” ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤.
ê°•ì›ë„_í™ì²œêµ°í˜ì´ì§€ ì •ë³´ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.
Processing rows: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 93/93 [11:25<00:00,  7.37s/it]
"""
st.text(log_text)
